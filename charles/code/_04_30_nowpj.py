# import lxml
# import time
# import math
import requests
from bs4 import BeautifulSoup
import pandas
import pprint as pp

# #ì¸ì½”ë”© ëì„ë•Œ
# service_key = '9VH8Dl7BNDE2r7qIa2XqmhsYk06C%2FeP%2BPppeVKS3lbCMbUMdL9pNWxQN3%2FpNKaTnvzf78DW%2FYmXEIn5V1YVcGg%3D%3D'

# #ì¸ì½”ë”© ì•ˆëì„ë•Œ
# # service_key = rq.parse.quote(service_key, encoding='utf-8')

# # ì¸ì¦í‚¤ í¬í•¨ ì£¼ì†Œ
# url = 'http://apis.data.go.kr/B552584/EvCharger/getChargerStatus'
# params = {'serviceKey': service_key,
#           'returnType': 'csv',
#           'pageNo': '1',
#           'numOfRows': '10',
#           'period': '5',
#           'zcode': '11'}

# response = requests.get(url, params=params)

# query = f"?ServiceKey={service_key}&returnType={returnType}&startDate={startdate}&endDate={enddate}"

# res = re.get(url + query)
# res.status_code
# dict_data = xtd.parse(res.text)
# pp.pprint(dict_data)


# import requests
# import urllib.parse

# service_key = 'yFqQ2sFmBBqWL89z46gTWtfoYGz%2FRUJahEHMHDPnBdq4Bg0gnpViM9SDHXfzOBUNWJttFBWZKzt3N%2Bc19phBqg%3D%3D'
# encoded_key = urllib.parse.quote(service_key, safe='')  # safe=''ë¡œ ì™„ì „ ì¸ì½”ë”©

# url = "http://apis.data.go.kr/B552584/EvCharger/getChargerInfo"
# params = {
#     'serviceKey': encoded_key,
#     'numOfRows': 10,
#     'pageNo': 1,
#     'dataType': 'JSON'
# }

# response = requests.get(url, params=params)

# print("ì‘ë‹µ ìƒíƒœ ì½”ë“œ:", response.status_code)
# print("ì‘ë‹µ ë³¸ë¬¸ (ì¼ë¶€):", response.text[:500])  # ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ ì¶œë ¥

# # JSON íŒŒì‹± ì‹œë„
# try:
#     data = response.json()
#     print("JSON íŒŒì‹± ì„±ê³µ!")
# except Exception as e:
#     print("JSON íŒŒì‹± ì‹¤íŒ¨:", e)


# # ì¸ì¦í‚¤ (ë°œê¸‰ë°›ì€ ì¸ì¦í‚¤ë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš”. ë°˜ë“œì‹œ URL ì¸ì½”ë”©ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)
# service_key = '9VH8Dl7BNDE2r7qIa2XqmhsYk06C%2FeP%2BPppeVKS3lbCMbUMdL9pNWxQN3%2FpNKaTnvzf78DW%2FYmXEIn5V1YVcGg%3D%3D'
# encoded_key = urllib.parse.quote(service_key)

# # ìš”ì²­ URL êµ¬ì„±
# url = f"http://apis.data.go.kr/B552584/EvCharger/getChargerInfo"
# params = {
#     'serviceKey': encoded_key,
#     'numOfRows': 10,
#     'pageNo': 1,
#     'dataType': 'JSON',  # ë˜ëŠ” 'XML'
#     # í•„ìš” ì‹œ ì•„ë˜ ì˜µì…˜ë„ ì¶”ê°€ ê°€ëŠ¥
#     # 'zcode': '11',  # ì„œìš¸íŠ¹ë³„ì‹œ
#     # 'zscode': '11680',  # ê°•ë‚¨êµ¬
#     # 'kind': 'F0',  # ì°¨ëŸ‰ì •ë¹„ì‹œì„¤
#     # 'kindDetail': 'F002'  # ì •ë¹„ì†Œ
# }

# response = requests.get(url, params=params)
# if response.status_code == 200:
#     data = response.json()
#     items = data.get('items', {}).get('item', [])
#     for item in items:
#         print(f"ì¶©ì „ì†Œëª…: {item.get('statNm')}")
#         print(f"ì£¼ì†Œ: {item.get('addr')} {item.get('addrDetail', '')}")
#         print(f"ì¶©ì „ê¸°ID: {item.get('chgerId')}")
#         print(f"ì¶©ì „ìƒíƒœ: {item.get('stat')}")
#         print("-" * 40)
# else:
#     print("API ìš”ì²­ ì‹¤íŒ¨:", response.status_code)


# # ------------------------------------------------------------
# response.content
# print(response.content)


# XML ìƒì„±í•˜ê¸°

# req = requests.get(url)
# req.content

# soup = BeautifulSoup(req.content, "lxml")  # XML ìƒì„±

# # ë°ì´í„° ê°€ê³µ
# # xml í˜•íƒœë¥¼ pandas dataframeìœ¼ë¡œ ë§Œë“¤ê¸°
# years = soup.find_all('acc_year')         # ì ‘ìˆ˜ë…„ì›”
# sgg_cds = soup.find_all('sgg_cd')           # ìì¹˜êµ¬ì½”ë“œ
# sgg_nms = soup.find_all('sgg_nm')           # ìì¹˜êµ¬ëª…
# bjdong_cds = soup.find_all('bjdong_cd')        # ë²•ì •ë™ì½”ë“œ
# bjdong_nms = soup.find_all('bjdong_nm')        # ë²•ì •ë™ëª…
# land_gbns = soup.find_all('land_gbn')         # ì§€ë²ˆêµ¬ë¶„
# land_gbn_nms = soup.find_all('land_gbn_nm')      # ì§€ë²ˆêµ¬ë¶„ëª…
# land_gbn_nms = soup.find_all('land_gbn_nm')      # ì§€ë²ˆêµ¬ë¶„ëª…
# bonbeons = soup.find_all('bonbeon')          # ë³¸ë²ˆ
# bubeons = soup.find_all('bubeon')           # ë¶€ë²ˆ
# bldg_nms = soup.find_all('bldg_nm')          # ê±´ë¬¼ëª…
# deal_ymds = soup.find_all('deal_ymd')         # ê³„ì•½ì¼
# obj_amts = soup.find_all('obj_amt')          # ë¬¼ê±´ê¸ˆì•¡(ë§Œì›)
# bldg_areas = soup.find_all('bldg_area')        # ê±´ë¬¼ë©´ì (ã¡)
# tot_areas = soup.find_all('tot_area')         # í† ì§€ë©´ì (ã¡)
# floors = soup.find_all('floor')            # ì¸µ
# right_gbns = soup.find_all('right_gbn')        # ê¶Œë¦¬êµ¬ë¶„
# cntl_ymds = soup.find_all('cntl_ymd')         # ì·¨ì†Œì¼
# build_years = soup.find_all('build_years')      # ê±´ì¶•ë…„ë„
# house_types = soup.find_all('house_type')       # ê±´ë¬¼ìš©ë„
# req_gbn = soup.find_all('req_gbn')          # ì‹ ê³ êµ¬ë¶„
# rdealer_lawdnms = soup.find_all('rdealer_lawdnm')   # ì‹ ê³ í•œ ê°œì—…ê³µì¸ì¤‘ê°œì‚¬ ì‹œêµ°êµ¬ëª…

# # ë°˜ë³µë¬¸ í™œìš©
# year_list = []
# sgg_cd_list = []
# bldg_nm_list = []
# obj_amt_list = []
# house_type_list = []
# rdealer_lawdnm_list = []

# for year, sgg_cd, bldg_nm, obj_amt, house_type, rdealer_lawdnm in zip(years, sgg_cds, bldg_nms, obj_amts, house_types, rdealer_lawdnms):
#   year_list.append(year.get_text())
#   sgg_cd_list.append(sgg_cd.get_text())
#   bldg_nm_list.append(bldg_nm.get_text())
#   obj_amt_list.append(obj_amt.get_text())
#   house_type_list.append(house_type.get_text())
#   rdealer_lawdnm_list.append(rdealer_lawdnm.get_text())

# df = pd.DataFrame({
#     "acc_year": year_list,
#     "sgg_cd": sgg_cd_list,
#     "bldg_nm": bldg_nm_list,
#     "obj_amt": obj_amt_list,
#     "house_type": house_type_list,
#     "rdealer_lawdnm": rdealer_lawdnm_list
# })


import requests
import xml.etree.ElementTree as ET
import csv


# url = 'http://apis.data.go.kr/B552584/EvCharger/getChargerInfo'
# params = {'serviceKey': 'yFqQ2sFmBBqWL89z46gTWtfoYGz/RUJahEHMHDPnBdq4Bg0gnpViM9SDHXfzOBUNWJttFBWZKzt3N+c19phBqg==',
#           'pageNo': '1', 'numOfRows': '10', 'period': '5', 'zcode': '11'}

# response = requests.get(url, params=params)
# print(response.content)

# response.encoding = 'utf-8'  # ì‘ë‹µ ì¸ì½”ë”© ì„¤ì • (ì¤‘ìš”!)

# # XML íŒŒì‹±
# root = ET.fromstring(response.text)
# items = root.findall(".//item")

# # CSV íŒŒì¼ë¡œ ì €ì¥
# with open("ì¶©ì „ì†Œ_ì •ë³´.csv", mode="w", newline="", encoding="utf-8-sig") as file:
#     writer = csv.writer(file)

#     # CSV í—¤ë” ì‘ì„±
#     writer.writerow([
#         "ì¶©ì „ì†Œëª…", "ì£¼ì†Œ", "ìƒì„¸ì£¼ì†Œ", "ì¶©ì „ê¸°ID", "ì¶©ì „ë°©ì‹", "ì¶©ì „ìƒíƒœ", "ì„¤ì¹˜ë…„ë„"
#     ])

#     for item in items:
#         statNm = item.findtext("statNm", "")
#         addr = item.findtext("addr", "")
#         addrDetail = item.findtext("addrDetail", "")
#         chgerId = item.findtext("chgerId", "")
#         method = item.findtext("method", "")
#         stat = item.findtext("stat", "")
#         year = item.findtext("year", "")

#         # ìƒíƒœ ì½”ë“œ ë§¤í•‘
#         status_map = {
#             "1": "í†µì‹ ì´ìƒ",
#             "2": "ì‚¬ìš©ê°€ëŠ¥",
#             "3": "ì¶©ì „ì¤‘",
#             "4": "ìš´ì˜ì¤‘ì§€",
#             "5": "ì ê²€ì¤‘",
#             "9": "ìƒíƒœë¯¸í™•ì¸"
#         }
#         stat_desc = status_map.get(stat, "ì•Œ ìˆ˜ ì—†ìŒ")

#         # í•œ ì¤„ ì‘ì„±
#         writer.writerow(
#             [statNm, addr, addrDetail, chgerId, method, stat_desc, year])

# print("âœ… 'ì¶©ì „ì†Œ_ì •ë³´.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!")

from requests.adapters import HTTPAdapter
from urllib3.poolmanager import PoolManager
import ssl
import certifi


service_key = "yFqQ2sFmBBqWL89z46gTWtfoYGz/RUJahEHMHDPnBdq4Bg0gnpViM9SDHXfzOBUNWJttFBWZKzt3N+c19phBqg=="

# ì„¤ì •ê°’
base_url = "http://apis.data.go.kr/B552584/EvCharger/getChargerStatus"

# # ssl ì—ëŸ¬ í™•ì¸ìš©
# class TLSAdapter(HTTPAdapter):
#     def init_poolmanager(self, *args, **kwargs):
#         kwargs['ssl_version'] = ssl.PROTOCOL_TLSv1_2
#         kwargs['cert_reqs'] = ssl.CERT_REQUIRED
#         kwargs['ca_certs'] = certifi.where()
#         return super().init_poolmanager(*args, **kwargs)


# session = requests.Session()
# session.mount('https://', TLSAdapter())

# url = base_url  # ì‹¤ì œ URLë¡œ ë°”ê¿”ì£¼ì„¸ìš”

# response = session.get(url)
# print(response.text)

params_base = {
    "serviceKey": service_key,
    "dataType": "XML",
    "numOfRows": 500,  # ìµœëŒ€ 9999
    "pageNo": 1
}

# ë¨¼ì € 1í˜ì´ì§€ í˜¸ì¶œí•˜ì—¬ ì „ì²´ ê±´ìˆ˜ í™•ì¸
response = requests.get(base_url, params=params_base, verify=certifi.where())
response.encoding = 'utf-8'
root = ET.fromstring(response.text)
total_count = int(root.findtext(".//totalCount", default="0"))
print(f"ğŸ” ì „ì²´ ì¶©ì „ì†Œ ìˆ˜: {total_count}ê±´")

# í˜ì´ì§€ ìˆ˜ ê³„ì‚°
num_per_page = params_base["numOfRows"]
total_pages = (total_count + num_per_page - 1) // num_per_page

# CSV íŒŒì¼ ì—´ê¸°
with open("ì¶©ì „ì†Œ_ì „ì²´ì •ë³´2.csv", mode="w", newline="", encoding="utf-8-sig") as file:
    writer = csv.writer(file)
    writer.writerow([
        "ì¶©ì „ì†Œëª…", "ì£¼ì†Œ", "ìƒì„¸ì£¼ì†Œ", "ì¶©ì „ê¸°ID", "ì¶©ì „ë°©ì‹", "ì¶©ì „ìƒíƒœ", "ì„¤ì¹˜ë…„ë„"
    ])

    # í˜ì´ì§€ ìˆœíšŒ
    for page in range(1, total_pages + 1):
        params_base["pageNo"] = page
        response = requests.get(base_url, params=params_base)
        response.encoding = 'utf-8'
        root = ET.fromstring(response.text)
        items = root.findall(".//item")

        for item in items:
            statNm = item.findtext("statNm", "")
            addr = item.findtext("addr", "")
            addrDetail = item.findtext("addrDetail", "")
            chgerId = item.findtext("chgerId", "")
            method = item.findtext("method", "")
            stat = item.findtext("stat", "")
            year = item.findtext("year", "")

            status_map = {
                "1": "í†µì‹ ì´ìƒ",
                "2": "ì‚¬ìš©ê°€ëŠ¥",
                "3": "ì¶©ì „ì¤‘",
                "4": "ìš´ì˜ì¤‘ì§€",
                "5": "ì ê²€ì¤‘",
                "9": "ìƒíƒœë¯¸í™•ì¸"
            }
            stat_desc = status_map.get(stat, "ì•Œ ìˆ˜ ì—†ìŒ")

            writer.writerow([statNm, addr, addrDetail,
                            chgerId, method, stat_desc, year])

        print(f"ğŸ“„ {page} / {total_pages} í˜ì´ì§€ ì™„ë£Œ")

print("âœ… ì „ì²´ ì¶©ì „ì†Œ ì •ë³´ê°€ 'ì¶©ì „ì†Œ_ì „ì²´ì •ë³´.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")


# --------------------------------------------------------------------------------------------------------
# service_key = "yFqQ2sFmBBqWL89z46gTWtfoYGz/RUJahEHMHDPnBdq4Bg0gnpViM9SDHXfzOBUNWJttFBWZKzt3N+c19phBqg=="

# # ì„¤ì •ê°’
# base_url = "http://apis.data.go.kr/B552584/EvCharger/getChargerInfo"
# params_base = {
#     "serviceKey": service_key,
#     "dataType": "XML",
#     "numOfRows": 300,  # ìµœëŒ€ 9999
#     "pageNo": 1
# }

# # ë¨¼ì € 1í˜ì´ì§€ í˜¸ì¶œí•˜ì—¬ ì „ì²´ ê±´ìˆ˜ í™•ì¸
# response = requests.get(base_url, params=params_base)
# response.encoding = 'utf-8'
# root = ET.fromstring(response.text)
# total_count = int(root.findtext(".//totalCount", default="0"))
# print(f"ğŸ” ì „ì²´ ì¶©ì „ì†Œ ìˆ˜: {total_count}ê±´")

# # í˜ì´ì§€ ìˆ˜ ê³„ì‚°
# num_per_page = params_base["numOfRows"]
# total_pages = (total_count + num_per_page - 1) // num_per_page

# # CSV íŒŒì¼ ì—´ê¸°
# with open("ì¶©ì „ì†Œ_ì „ì²´ì •ë³´.csv", mode="w", newline="", encoding="utf-8-sig") as file:
#     writer = csv.writer(file)
#     writer.writerow([
#         "ì¶©ì „ì†Œëª…", "ì£¼ì†Œ", "ìƒì„¸ì£¼ì†Œ", "ì¶©ì „ê¸°ID", "ì¶©ì „ë°©ì‹", "ì¶©ì „ìƒíƒœ", "ì„¤ì¹˜ë…„ë„"
#     ])

#     # í˜ì´ì§€ ìˆœíšŒ
#     for page in range(1, total_pages + 1):
#         params_base["pageNo"] = page
#         response = requests.get(base_url, params=params_base)
#         response.encoding = 'utf-8'
#         root = ET.fromstring(response.text)
#         items = root.findall(".//item")

#         for item in items:
#             statNm = item.findtext("statNm", "")
#             addr = item.findtext("addr", "")
#             addrDetail = item.findtext("addrDetail", "")
#             chgerId = item.findtext("chgerId", "")
#             method = item.findtext("method", "")
#             stat = item.findtext("stat", "")
#             year = item.findtext("year", "")

#             status_map = {
#                 "1": "í†µì‹ ì´ìƒ",
#                 "2": "ì‚¬ìš©ê°€ëŠ¥",
#                 "3": "ì¶©ì „ì¤‘",
#                 "4": "ìš´ì˜ì¤‘ì§€",
#                 "5": "ì ê²€ì¤‘",
#                 "9": "ìƒíƒœë¯¸í™•ì¸"
#             }
#             stat_desc = status_map.get(stat, "ì•Œ ìˆ˜ ì—†ìŒ")

#             writer.writerow([statNm, addr, addrDetail,
#                             chgerId, method, stat_desc, year])

#         print(f"ğŸ“„ {page} / {total_pages} í˜ì´ì§€ ì™„ë£Œ")

# print("âœ… ì „ì²´ ì¶©ì „ì†Œ ì •ë³´ê°€ 'ì¶©ì „ì†Œ_ì „ì²´ì •ë³´.csv'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
